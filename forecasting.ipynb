{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b39242e8-f5d8-49e6-9b8c-2ac92dffa9e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, glob, json, time, math, random\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f13a71-604a-4bf5-81cf-b6da6fdff99d",
   "metadata": {},
   "source": [
    "### Pointing towards the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "effd3947-77ac-47f5-9c69-b55d16ac24bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   Unnamed: 0      Name           ID      Lat       Lon  \\\n",
       " 0           1    Lander  USW00024021  42.8153 -108.7261   \n",
       " 1           2    Lander  USW00024021  42.8153 -108.7261   \n",
       " 2           3  Cheyenne  USW00024018  41.1519 -104.8061   \n",
       " 3           4  Cheyenne  USW00024018  41.1519 -104.8061   \n",
       " 4           5    Wausau  USW00014897  44.9258  -89.6256   \n",
       " \n",
       "                   Stn.Name  Stn.stDate  Stn.edDate  \n",
       " 0               LANDER WBO  1892-01-01  1946-05-28  \n",
       " 1        LANDER HUNT FIELD  1946-05-29  2023-12-31  \n",
       " 2             CHEYENNE WBO  1871-01-01  1935-08-31  \n",
       " 3  CHEYENNE MUNICIPAL ARPT  1935-09-01  2023-12-31  \n",
       " 4     Wausau Record Herald  1896-01-01  1941-12-31  ,\n",
       " (461, 8))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = \"7890488\"\n",
    "CITY_INFO_PATH = os.path.join(DATA_DIR, \"city_info.csv\")\n",
    "\n",
    "assert os.path.exists(DATA_DIR), f\"Missing folder: {DATA_DIR}\"\n",
    "assert os.path.exists(CITY_INFO_PATH), f\"Missing file: {CITY_INFO_PATH}\"\n",
    "\n",
    "city_info = pd.read_csv(CITY_INFO_PATH)\n",
    "city_info.head(), city_info.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f986053b-4680-4e52-bc08-ea191231cd2a",
   "metadata": {},
   "source": [
    "### Identify individual city files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0170f396-dae7-4c03-acbd-08d4cb9cd649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total CSV files: 211\n",
      "City files: 210\n",
      "Example: USW00003822.csv\n"
     ]
    }
   ],
   "source": [
    "all_files = glob.glob(os.path.join(DATA_DIR, \"*.csv\"))\n",
    "city_files = [p for p in all_files if os.path.basename(p).lower() != \"city_info.csv\"]\n",
    "\n",
    "print(\"Total CSV files:\", len(all_files))\n",
    "print(\"City files:\", len(city_files))\n",
    "print(\"Example:\", os.path.basename(city_files[0]) if city_files else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d9971e-1b78-44bf-8af6-c583c69e3bd9",
   "metadata": {},
   "source": [
    "### Load one city at a time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9a3e307-9c6c-4230-8611-4a9879f9568d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   Unnamed: 0        Date  tmax  tmin  prcp\n",
       " 0           1  1871-01-01   NaN   NaN   0.0\n",
       " 1           2  1871-01-02   NaN   NaN   0.0\n",
       " 2           3  1871-01-03   NaN   NaN   0.0\n",
       " 3           4  1871-01-04   NaN   NaN   0.0\n",
       " 4           5  1871-01-05   NaN   NaN   0.0,\n",
       " Index(['Unnamed: 0', 'Date', 'tmax', 'tmin', 'prcp'], dtype='object'),\n",
       " (55882, 5))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_path = city_files[0]\n",
    "df0 = pd.read_csv(sample_path)\n",
    "df0.head(), df0.columns, df0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0705ce01-5e13-46e2-9faa-aa1de001fb81",
   "metadata": {},
   "source": [
    "### Handling common naming variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3d2fcef-9cb9-414b-b60f-d64fdd25f472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_city_df(df: pd.DataFrame, city_id: str) -> pd.DataFrame:\n",
    "    cols = {c.lower(): c for c in df.columns}\n",
    "\n",
    "    date_col = cols.get(\"date\")\n",
    "    tmax_col = cols.get(\"tmax\") \n",
    "    tmin_col = cols.get(\"tmin\")\n",
    "    prcp_col = cols.get(\"prcp\")\n",
    "\n",
    "    out = df[[date_col, tmax_col, tmin_col, prcp_col]].copy()\n",
    "    out.columns = [\"date\", \"tmax\", \"tmin\", \"prcp\"]\n",
    "    out[\"date\"] = pd.to_datetime(out[\"date\"])\n",
    "    out[\"city_id\"] = city_id\n",
    "\n",
    "    for c in [\"tmax\", \"tmin\", \"prcp\"]:\n",
    "        out[c] = pd.to_numeric(out[c], errors=\"coerce\")\n",
    "\n",
    "    out = out.sort_values(\"date\").reset_index(drop=True)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4c1b76-4108-4a88-ba7b-0895580a3d4d",
   "metadata": {},
   "source": [
    "### Loading `n` cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02ad7647-74fc-4db4-ae98-ab51fc1d43fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "533776d174ff4699ae76f61450d24315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(        date  tmax  tmin  prcp      city_id\n",
       " 0 1871-01-01   NaN   NaN   0.0  USW00003822\n",
       " 1 1871-01-02   NaN   NaN   0.0  USW00003822\n",
       " 2 1871-01-03   NaN   NaN   0.0  USW00003822\n",
       " 3 1871-01-04   NaN   NaN   0.0  USW00003822\n",
       " 4 1871-01-05   NaN   NaN   0.0  USW00003822,\n",
       " (1273229, 5))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def city_id_from_path(p: str) -> str:\n",
    "    return os.path.splitext(os.path.basename(p))[0]\n",
    "\n",
    "N_CITIES = 25\n",
    "selected_paths = city_files[:N_CITIES]\n",
    "\n",
    "frames = []\n",
    "for p in tqdm(selected_paths):\n",
    "    cid = city_id_from_path(p)\n",
    "    df = pd.read_csv(p)\n",
    "    frames.append(standardize_city_df(df, cid))\n",
    "\n",
    "data = pd.concat(frames, ignore_index=True)\n",
    "data.head(), data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af564db7-df70-42c3-bb91-54d4a1d78a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city_info columns: ['Unnamed: 0', 'Name', 'ID', 'Lat', 'Lon', 'Stn.Name', 'Stn.stDate', 'Stn.edDate']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "lat    0.0\n",
       "lon    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_cols = {c.lower(): c for c in city_info.columns}\n",
    "print(\"city_info columns:\", city_info.columns.tolist())\n",
    "\n",
    "CITY_ID_COL = lower_cols.get(\"id\")\n",
    "LAT_COL = lower_cols.get(\"lat\")\n",
    "LON_COL = lower_cols.get(\"lon\")\n",
    "\n",
    "assert CITY_ID_COL and LAT_COL and LON_COL, \"Fix CITY_ID_COL/LAT_COL/LON_COL based on city_info columns.\"\n",
    "\n",
    "meta = city_info[[CITY_ID_COL, LAT_COL, LON_COL]].copy()\n",
    "meta.columns = [\"city_id\", \"lat\", \"lon\"]\n",
    "\n",
    "data = data.merge(meta, on=\"city_id\", how=\"left\")\n",
    "data[[\"lat\",\"lon\"]].isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd76bb05-3e61-4cda-9a1c-aaf5c7bc401d",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3eac01-a6dc-43f1-ba38-4719b2cb14ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    d = df.copy()\n",
    "    d[\"year\"] = d[\"date\"].dt.year\n",
    "    d[\"month\"] = d[\"date\"].dt.month\n",
    "    d[\"dayofyear\"] = d[\"date\"].dt.dayofyear\n",
    "    d[\"sin_doy\"] = np.sin(2*np.pi*d[\"dayofyear\"]/365.25)\n",
    "    d[\"cos_doy\"] = np.cos(2*np.pi*d[\"dayofyear\"]/365.25)\n",
    "    return d\n",
    "\n",
    "def add_lags(df: pd.DataFrame, lags=(1, 7, 30)) -> pd.DataFrame:\n",
    "    d = df.copy()\n",
    "    d = d.sort_values([\"city_id\",\"date\"])\n",
    "    for lag in lags:\n",
    "        for col in [\"tmax\",\"tmin\",\"prcp\"]:\n",
    "            d[f\"{col}_lag{lag}\"] = d.groupby(\"city_id\")[col].shift(lag)\n",
    "    return d\n",
    "\n",
    "data_fe = add_time_features(data)\n",
    "data_fe = add_lags(data_fe, lags=(1, 7, 30))\n",
    "\n",
    "# this targets the next day\n",
    "for col in [\"tmax\",\"tmin\",\"prcp\"]:\n",
    "    data_fe[f\"{col}_target\"] = data_fe.groupby(\"city_id\")[col].shift(-1)\n",
    "\n",
    "feature_cols = [\"lat\",\"lon\",\"sin_doy\",\"cos_doy\"] + \\\n",
    "              [f\"{c}_lag{l}\" for l in (1,7,30) for c in (\"tmax\",\"tmin\",\"prcp\")]\n",
    "target_cols = [\"tmax_target\",\"tmin_target\",\"prcp_target\"]\n",
    "\n",
    "model_df = data_fe.dropna(subset=feature_cols + target_cols).reset_index(drop=True)\n",
    "model_df.head(), model_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fdb8b9-00b9-4841-9fb7-73b993dbc9f7",
   "metadata": {},
   "source": [
    "### Tine based split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79bf35b-a2a4-44b4-83ce-3a55347e41ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = model_df[\"date\"]\n",
    "train_end = pd.Timestamp(\"2016-12-31\")\n",
    "val_end   = pd.Timestamp(\"2019-12-31\")\n",
    "\n",
    "train_df = model_df[dates <= train_end].copy()\n",
    "val_df   = model_df[(dates > train_end) & (dates <= val_end)].copy()\n",
    "test_df  = model_df[dates > val_end].copy()\n",
    "\n",
    "len(train_df), len(val_df), len(test_df), (train_df[\"date\"].min(), test_df[\"date\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991c4869-1eaf-4ef2-8d8e-ef515cbfed25",
   "metadata": {},
   "source": [
    "### Scaling features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e398cf-d4f6-41cf-b60e-1eb21e600d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df[feature_cols].values.astype(np.float32)\n",
    "y_train = train_df[target_cols].values.astype(np.float32)\n",
    "\n",
    "X_val = val_df[feature_cols].values.astype(np.float32)\n",
    "y_val = val_df[target_cols].values.astype(np.float32)\n",
    "\n",
    "X_test = test_df[feature_cols].values.astype(np.float32)\n",
    "y_test = test_df[target_cols].values.astype(np.float32)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train).astype(np.float32)\n",
    "X_val_s   = scaler.transform(X_val).astype(np.float32)\n",
    "X_test_s  = scaler.transform(X_test).astype(np.float32)\n",
    "\n",
    "class TabDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X)\n",
    "        self.y = torch.from_numpy(y)\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, i): return self.X[i], self.y[i]\n",
    "\n",
    "BATCH_SIZE = 8192\n",
    "train_loader = DataLoader(TabDataset(X_train_s, y_train), batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader   = DataLoader(TabDataset(X_val_s, y_val), batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader  = DataLoader(TabDataset(X_test_s, y_test), batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5162d2fe-fc4f-432a-8b2f-e211b41e5a0f",
   "metadata": {},
   "source": [
    "### GPU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b2b8b6-ba59-4309-999b-059e7b54f6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim: int, out_dim: int = 3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, out_dim),\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "model = MLP(in_dim=len(feature_cols), out_dim=len(target_cols)).to(DEVICE)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.SmoothL1Loss()\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232deed7-a60a-4794-99d5-34cac7033bfe",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1696d246-f8cc-41bb-97a2-d95b30ebcbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(model, loader, train: bool):\n",
    "    model.train(train)\n",
    "    total_loss = 0.0\n",
    "    n = 0\n",
    "    for Xb, yb in loader:\n",
    "        Xb = Xb.to(DEVICE, non_blocking=True)\n",
    "        yb = yb.to(DEVICE, non_blocking=True)\n",
    "        if train:\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "        pred = model(Xb)\n",
    "        loss = loss_fn(pred, yb)\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        bs = Xb.size(0)\n",
    "        total_loss += loss.item() * bs\n",
    "        n += bs\n",
    "    return total_loss / max(n, 1)\n",
    "\n",
    "EPOCHS = 10\n",
    "history = []\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    tr_loss = run_epoch(model, train_loader, train=True)\n",
    "    va_loss = run_epoch(model, val_loader, train=False)\n",
    "    history.append({\"epoch\": epoch, \"train_loss\": tr_loss, \"val_loss\": va_loss})\n",
    "    print(f\"Epoch {epoch:02d} | train {tr_loss:.4f} | val {va_loss:.4f}\")\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(\"Elapsed seconds:\", elapsed)\n",
    "print(\"Device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaff0ea-81d1-4201-bc5f-66e13c956f45",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980ecc5e-2438-4bf3-a7c0-800cf19aee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_all(model, loader):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    trues = []\n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in loader:\n",
    "            Xb = Xb.to(DEVICE, non_blocking=True)\n",
    "            pred = model(Xb).cpu().numpy()\n",
    "            preds.append(pred)\n",
    "            trues.append(yb.numpy())\n",
    "    return np.vstack(preds), np.vstack(trues)\n",
    "\n",
    "pred, true = predict_all(model, test_loader)\n",
    "\n",
    "metrics = {}\n",
    "for i, name in enumerate(target_cols):\n",
    "    yhat = pred[:, i]\n",
    "    y    = true[:, i]\n",
    "    metrics[name] = {\n",
    "        \"MAE\": float(mean_absolute_error(y, yhat)),\n",
    "        \"RMSE\": float(mean_squared_error(y, yhat, squared=False)),\n",
    "    }\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820746ea-e353-4fc2-a3a8-679f2fb58ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"outputs/models\", exist_ok=True)\n",
    "os.makedirs(\"outputs/metrics\", exist_ok=True)\n",
    "\n",
    "torch.save(model.state_dict(), \"outputs/models/mlp_state.pt\")\n",
    "pd.DataFrame(history).to_csv(\"outputs/metrics/history.csv\", index=False)\n",
    "with open(\"outputs/metrics/test_metrics.json\", \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "import joblib\n",
    "joblib.dump(scaler, \"outputs/models/feature_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7faaf78-5383-421c-95e4-b309bcbd8e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
